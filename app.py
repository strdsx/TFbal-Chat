import os
import streamlit as st
from time import sleep

from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.schema import StrOutputParser
from langchain_core.runnables import RunnableLambda
from langchain_core.runnables import ConfigurableField
from operator import itemgetter
from PIL import Image
import templates

st.set_page_config(page_title="TF ê³ ë¯¼ìƒë‹´", page_icon="ðŸ¤”", layout="wide")

@st.cache_data
def avatar_load(t_path="./images/t_avatar.png", f_path="./images/f_avatar.png"):
    return (Image.open(t_path).resize((256,256)),
            Image.open(f_path).resize((256,256)))

# ----- Sidebar
with st.sidebar:
    openai_api_key = st.text_input(label='**OpenAI API Key**', placeholder='sk-...', type='password')
    model_disabled = True
    if openai_api_key == "":
        st.info('OpenAI API Keyë¥¼ ìž…ë ¥ í•´ì£¼ì„¸ìš”.', icon='ðŸ˜€')
    elif 'sk-' not in openai_api_key[:4]:
        st.warning('OpenAI API Key í˜•ì‹ì´ ìž˜ëª» ë˜ì—ˆìŠµë‹ˆë‹¤.', icon='ðŸ˜…')
    else:
        model_disabled = False

    model_name = st.selectbox(
        label="**Model**",
        options=('gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-1106', 'gpt-4', 'gpt-4-1106-preview'),
        index=0,
        disabled=model_disabled
        )
    # temper = st.number_input(label="**Temperature**", min_value=0.0, max_value=2.0, value=0.7, step=0.1, key='temperature')
    # memory = st.number_input(label='**Memory**', min_value=0, max_value=10, value=5, key='memory')

t_avatar, f_avatar = avatar_load()
st.title("ðŸ¤” TF ê³ ë¯¼ ìƒë‹´ ðŸ¤”")
with st.expander(label="**ì„¤ëª…** ðŸ‘‡", expanded=False):
    tava, fava = st.columns(2)
    tava.image(t_avatar.resize((128,128)), caption='T-bal')
    fava.image(f_avatar.resize((128,128)), caption='F-bal')

    tava.markdown("""- T-bal: MBTI :red[**T 100%**] ì±—ë´‡ ìž…ë‹ˆë‹¤.
- í˜„ì‹¤ì ì¸ í•´ê²°ì±…ì„ ì œì‹œí•˜ëŠ” ê²ƒì´ ì œì¼ ì¤‘ìš”í•©ë‹ˆë‹¤.
- í•­ìƒ ì´ì„±ì , ë…¼ë¦¬ì , ë¶„ì„ì ìœ¼ë¡œ ê°ê´€ì  ì‚¬ì‹¤ì— ê¸°ë°˜í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤.
- ìƒëŒ€ë°©ì˜ ê°ì •ì— ì‰½ê²Œ ê³µê°í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
""")
    fava.markdown("""- F-bal: MBTI :blue[**F 100%**] ì±—ë´‡ ìž…ë‹ˆë‹¤.
- í˜„ì‹¤ì ì¸ í•´ê²°ì±…ì„ ì œì‹œí•˜ëŠ” ê²ƒì€ ì¤‘ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ë…¼ë¦¬/ê°ê´€ì ì´ì§€ ì•Šì•„ë„, ìƒëŒ€ë°©ì˜ ê¸°ë¶„ì„ ìƒí•˜ì§€ ì•Šê²Œ ë‹µë³€í•˜ëŠ”ê²Œ ì œì¼ ì¤‘ìš”í•©ë‹ˆë‹¤.
- ìƒëŒ€ë°©ì˜ ê°ì •ì— ê³µê°ì„ ìž˜ í•©ë‹ˆë‹¤.
""")
    st.divider()
    st.markdown("""âš ï¸ **ì£¼ì˜ ì‚¬í•­**
- T-bal, F-bal ëª¨ë‘ ì´ì „ ëŒ€í™” ë‚´ì—­ì„ ê¸°ì–µí•˜ì§€ ëª»í•©ë‹ˆë‹¤.
- ë”°ë¼ì„œ í•­ìƒ ì™„ì„±ëœ ë…ë¦½í˜• ë©”ì„¸ì§€ë¥¼ ë³´ë‚´ì•¼ í•©ë‹ˆë‹¤.
- ëŒ€í™” ë‚´ì—­ì€ ìµœëŒ€ 30ê°œ ê¹Œì§€ë§Œ í‘œì¶œë˜ë©°, 30ê°œ ì´ˆê³¼ì‹œ ì˜¤ëž˜ëœ ëŒ€í™” ë‚´ì—­ ë¨¼ì € ì‚­ì œë©ë‹ˆë‹¤.
""")

query = st.chat_input("Send message...", disabled=model_disabled)

if model_disabled:
    st.warning("OpenAI API Keyë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.", icon='âœ‹')
    st.stop()

# ----- Chains
temper=0.7
memory=30

parser = StrOutputParser()
llm = ChatOpenAI(model=model_name, temperature=temper, openai_api_key=openai_api_key)
t_chain = PromptTemplate.from_template(templates.T_TEMPLATE) | llm | parser
f_chain = PromptTemplate.from_template(templates.F_TEMPLATE) | llm | parser

# ----- Chat history
if 't_history' not in st.session_state:
    st.session_state.t_history = []
else:
    if len(st.session_state.t_history) > memory:
        st.session_state.t_history = st.session_state.t_history[-memory:]

if 'f_history' not in st.session_state:
    st.session_state.f_history = []
else:
    if len(st.session_state.f_history) > memory:
        st.session_state.f_history = st.session_state.f_history[-memory:]


with st.container(border=False):
    # Write chat history
    if len(st.session_state.t_history) and len(st.session_state.f_history):
        for (q, ta), (_, fa) in zip(st.session_state.t_history, st.session_state.f_history):
            with st.chat_message("user"):
                st.markdown(q)

            tcol_, fcol_ = st.columns(2)
            with tcol_:
                with st.chat_message("ai", avatar=t_avatar):
                    st.markdown(ta)

            with fcol_:
                with st.chat_message("ai", avatar=f_avatar):
                    st.markdown(fa)

    # Write recent chat
    if query:
        with st.chat_message("user"):
            st.markdown(query)

        tcol, fcol = st.columns(2)
        with tcol:
            with st.chat_message("ai", avatar=t_avatar):
                t_answer = ""
                t_placeholder = st.empty()
                for tt in t_chain.stream({"question": query}):
                    t_answer += tt
                    t_placeholder.markdown(t_answer + "â–Œ")
                    sleep(0.005)
                t_placeholder.markdown(t_answer)
                st.session_state.t_history.append((query, t_answer))

        with fcol:
            with st.chat_message("ai", avatar=f_avatar):
                f_answer = ""
                f_placeholder = st.empty()
                for ft in f_chain.stream({"question": query}):
                    f_answer += ft
                    f_placeholder.markdown(f_answer)
                    sleep(0.005)
                f_placeholder.markdown(f_answer)
                st.session_state.f_history.append((query, f_answer))

