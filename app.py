import os
import streamlit as st
from time import sleep

from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.schema import StrOutputParser
from langchain_core.runnables import RunnableLambda
from langchain_core.runnables import ConfigurableField
from operator import itemgetter
from PIL import Image
import templates

st.set_page_config(page_title="TF Í≥†ÎØºÏÉÅÎã¥", page_icon="ü§î", layout="wide")

hide_css = """
<style>
#MainMenu {visibility: hidden;}
</style>
"""
st.markdown(hide_css, unsafe_allow_html=True)

@st.cache_data
def avatar_load(t_path="./images/t_avatar.png", f_path="./images/f_avatar.png"):
    return (Image.open(t_path).resize((256,256)),
            Image.open(f_path).resize((256,256)))

# ----- Sidebar
with st.sidebar:
    openai_api_key = st.text_input(label='**OpenAI API Key**', placeholder='sk-...', type='password')
    model_disabled = True
    if openai_api_key == "":
        st.info('OpenAI API KeyÎ•º ÏûÖÎ†• Ìï¥Ï£ºÏÑ∏Ïöî.', icon='üòÄ')
    elif 'sk-' not in openai_api_key[:4]:
        st.warning('OpenAI API Key ÌòïÏãùÏù¥ ÏûòÎ™ª ÎêòÏóàÏäµÎãàÎã§.', icon='üòÖ')
    else:
        model_disabled = False

    model_name = st.selectbox(
        label="**Model**",
        options=('gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-1106', 'gpt-4', 'gpt-4-1106-preview'),
        index=0,
        disabled=model_disabled
        )
    # temper = st.number_input(label="**Temperature**", min_value=0.0, max_value=2.0, value=0.7, step=0.1, key='temperature')
    # memory = st.number_input(label='**Memory**', min_value=0, max_value=10, value=5, key='memory')

t_avatar, f_avatar = avatar_load()
st.title("ü§î TF Í≥†ÎØº ÏÉÅÎã¥ ü§î")
with st.expander(label="**ÏÑ§Î™Ö** üëá", expanded=False):
    tava, fava = st.columns(2)
    tava.image(t_avatar.resize((128,128)), caption='T-bal')
    fava.image(f_avatar.resize((128,128)), caption='F-bal')

    tava.markdown("""- T-bal: MBTI :red[**T 100%**] Ï±óÎ¥á ÏûÖÎãàÎã§.
- ÌòÑÏã§Ï†ÅÏù∏ Ìï¥Í≤∞Ï±ÖÏùÑ Ï†úÏãúÌïòÎäî Í≤ÉÏù¥ Ï†úÏùº Ï§ëÏöîÌï©ÎãàÎã§.
- Ìï≠ÏÉÅ Ïù¥ÏÑ±Ï†Å, ÎÖºÎ¶¨Ï†Å, Î∂ÑÏÑùÏ†ÅÏúºÎ°ú Í∞ùÍ¥ÄÏ†Å ÏÇ¨Ïã§Ïóê Í∏∞Î∞òÌïòÏó¨ ÎãµÎ≥ÄÌï©ÎãàÎã§.
- ÏÉÅÎåÄÎ∞©Ïùò Í∞êÏ†ïÏóê ÏâΩÍ≤å Í≥µÍ∞êÌïòÏßÄ ÏïäÏäµÎãàÎã§.
""")
    fava.markdown("""- F-bal: MBTI :blue[**F 100%**] Ï±óÎ¥á ÏûÖÎãàÎã§.
- ÌòÑÏã§Ï†ÅÏù∏ Ìï¥Í≤∞Ï±ÖÏùÑ Ï†úÏãúÌïòÎäî Í≤ÉÏùÄ Ï§ëÏöîÌïòÏßÄ ÏïäÏäµÎãàÎã§.
- ÎÖºÎ¶¨/Í∞ùÍ¥ÄÏ†ÅÏù¥ÏßÄ ÏïäÏïÑÎèÑ, ÏÉÅÎåÄÎ∞©Ïùò Í∏∞Î∂ÑÏùÑ ÏÉÅÌïòÏßÄ ÏïäÍ≤å ÎãµÎ≥ÄÌïòÎäîÍ≤å Ï†úÏùº Ï§ëÏöîÌï©ÎãàÎã§.
- ÏÉÅÎåÄÎ∞©Ïùò Í∞êÏ†ïÏóê Í≥µÍ∞êÏùÑ Ïûò Ìï©ÎãàÎã§.
""")
    st.divider()
    st.markdown("""‚ö†Ô∏è **Ï£ºÏùò ÏÇ¨Ìï≠**
- T-bal, F-bal Î™®Îëê Ïù¥Ï†Ñ ÎåÄÌôî ÎÇ¥Ïó≠ÏùÑ Í∏∞ÏñµÌïòÏßÄ Î™ªÌï©ÎãàÎã§.
- Îî∞ÎùºÏÑú Ìï≠ÏÉÅ ÏôÑÏÑ±Îêú ÎèÖÎ¶ΩÌòï Î©îÏÑ∏ÏßÄÎ•º Î≥¥ÎÇ¥Ïïº Ìï©ÎãàÎã§.
- ÎåÄÌôî ÎÇ¥Ïó≠ÏùÄ ÏµúÎåÄ 30Í∞ú ÍπåÏßÄÎßå ÌëúÏ∂úÎêòÎ©∞, 30Í∞ú Ï¥àÍ≥ºÏãú Ïò§ÎûòÎêú ÎåÄÌôî ÎÇ¥Ïó≠ Î®ºÏ†Ä ÏÇ≠Ï†úÎê©ÎãàÎã§.
""")

query = st.chat_input("Send message...", disabled=model_disabled)

if model_disabled:
    st.warning("OpenAI API KeyÎ•º ÌôïÏù∏Ìï¥ Ï£ºÏÑ∏Ïöî.", icon='‚úã')
    st.stop()

# ----- Chains
temper=0.7
memory=30

parser = StrOutputParser()
llm = ChatOpenAI(model=model_name, temperature=temper, openai_api_key=openai_api_key)
t_chain = PromptTemplate.from_template(templates.T_TEMPLATE) | llm | parser
f_chain = PromptTemplate.from_template(templates.F_TEMPLATE) | llm | parser

# ----- Chat history
if 't_history' not in st.session_state:
    st.session_state.t_history = []
else:
    if len(st.session_state.t_history) > memory:
        st.session_state.t_history = st.session_state.t_history[-memory:]

if 'f_history' not in st.session_state:
    st.session_state.f_history = []
else:
    if len(st.session_state.f_history) > memory:
        st.session_state.f_history = st.session_state.f_history[-memory:]


with st.container(border=False):
    # Write chat history
    if len(st.session_state.t_history) and len(st.session_state.f_history):
        for (q, ta), (_, fa) in zip(st.session_state.t_history, st.session_state.f_history):
            with st.chat_message("user"):
                st.markdown(q)

            tcol_, fcol_ = st.columns(2)
            with tcol_:
                with st.chat_message("ai", avatar=t_avatar):
                    st.markdown(ta)

            with fcol_:
                with st.chat_message("ai", avatar=f_avatar):
                    st.markdown(fa)

    # Write recent chat
    if query:
        with st.chat_message("user"):
            st.markdown(query)

        tcol, fcol = st.columns(2)
        with tcol:
            with st.chat_message("ai", avatar=t_avatar):
                t_answer = ""
                t_placeholder = st.empty()
                for tt in t_chain.stream({"question": query}):
                    t_answer += tt
                    t_placeholder.markdown(t_answer + "‚ñå")
                    sleep(0.005)
                t_placeholder.markdown(t_answer)
                st.session_state.t_history.append((query, t_answer))

        with fcol:
            with st.chat_message("ai", avatar=f_avatar):
                f_answer = ""
                f_placeholder = st.empty()
                for ft in f_chain.stream({"question": query}):
                    f_answer += ft
                    f_placeholder.markdown(f_answer)
                    sleep(0.005)
                f_placeholder.markdown(f_answer)
                st.session_state.f_history.append((query, f_answer))

